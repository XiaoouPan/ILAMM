% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/RcppExports.R
\name{ncvxHuberReg}
\alias{ncvxHuberReg}
\title{Non-convex regularized Huber regression}
\usage{
ncvxHuberReg(X, Y, lambda = -1, penalty = "SCAD", tau = -1,
  phi0 = 0.001, gamma = 1.5, epsilon_c = 1e-04, epsilon_t = 1e-04,
  iteMax = 500L, intercept = FALSE, itcpIncluded = FALSE)
}
\arguments{
\item{X}{An \eqn{n} by \eqn{d} design matrix with each row being a sample and each column being a variable, either low-dimensional data (\eqn{d \le n}) or high-dimensional data (\eqn{d > n}) are allowed.}

\item{Y}{A continuous response vector with length \eqn{n}.}

\item{lambda}{Tuning parameter of regularized regression, its specified value should be positive. The default value is determined in this way: define \eqn{\lambda_max = max(|Y^T X|) / n}, and \eqn{\lambda_min = 0.01 * \lambda_max}, then \eqn{\lambda = exp(0.7 * log(\lambda_max) + 0.3 * log(\lambda_min))}.}

\item{penalty}{Type of non-convex penalties with default setting "SCAD", possible choices are: "Lasso", "SCAD" and "MCP".}

\item{tau}{Robustness parameter of Huber loss function, its specified value should be positive. The default value is determined in this way: define \eqn{R} as the residual from Lasso by fitting \code{ncvxReg} with \code{lambda}, and \eqn{\sigma_MAD = median(|R - median(R)|) / \Phi^(-1)(3/4)} is the median absolute deviation estimator, then \eqn{\tau = \sigma_MAD \sqrt(n / log(nd))}.}

\item{phi0}{The initial value of the isotropic parameter \eqn{\phi} in I-LAMM algorithm. The defalut value is 0.001.}

\item{gamma}{The inflation parameter in I-LAMM algorithm, in each iteration of I-LAMM, we will inflate \eqn{\phi} by \eqn{\gamma}. The defalut value is 1.5.}

\item{epsilon_c}{The tolerance level for contraction stage, iteration of contraction will stop when \eqn{||\beta_new - \beta_old||_2 / \sqrt(d + 1) < \epsilon_c}. The defalut value is 1e-4.}

\item{epsilon_t}{The tolerance level for tightening stage, iteration of tightening will stop when \eqn{||\beta_new - \beta_old||_2 / \sqrt(d + 1) < \epsilon_t}. The defalut value is 1e-4.}

\item{iteMax}{The maximal number of iteration in either contraction or tightening stage, if this number is reached, the convergence of I-LAMM is failed. The defalut value is 500.}

\item{intercept}{Boolean value indicating whether an intercept term should be included into the model. The default setting is \code{FALSE}.}

\item{itcpIncluded}{Boolean value indicating whether a column of 1's has been included in the design matrix \eqn{X}. The default setting is \code{FALSE}.}
}
\value{
A list including the following terms will be returned:
\itemize{
\item \code{beta} The estimated \eqn{\beta}, a vector with length d + 1, with the first one being the value of intercept (0 if \code{intercept = FALSE}).
\item \code{phi} The final value of the isotropic parameter \eqn{\phi} in the last iteration of I-LAMM algorithm.
\item \code{penalty} The type of penalty.
\item \code{lambda} The value of \eqn{\lambda}.
\item \code{tau} The value of \eqn{\tau}.
\item \code{IteTightening} The number of tightenings in I-LAMM algorithm, and it's 0 if \code{penalty = "Lasso"}.
}
}
\description{
The function fits (high-dimensional) Huber regularized regression with non-convex penalties: Lasso, SCAD and MCP, and it's implemented via I-LAMM algorithm.
}
\details{
The observed data are \eqn{(Y, X)}, where \eqn{Y} is an \eqn{n}-dimensional response vector and \eqn{X} is an \eqn{n} by \eqn{d} design matrix. We assume that \eqn{Y} depends on \eqn{X} through a linear model \eqn{Y = X \beta + \epsilon}, where \eqn{\epsilon} is an \eqn{n}-dimensional noise vector whose distribution can be asymmetrix and/or heavy-tailed. The design matrix \eqn{X} can be either high-dimensional or low-dimensional. Tunning parameters \eqn{\lambda} and \eqn{\tau} have default settings but they can be user-specified. All the arguments except for \eqn{X} and \eqn{Y} have default settings.
}
\examples{
n = 50
d = 100
set.seed(2018)
X = matrix(rnorm(n * d), n, d)
beta = c(rep(2, 3), rep(0, d - 3))
Y = X \%*\% beta + rlnorm(n, 0, 1.2) - exp(1.2^2 / 2)
# Fit Huber-SCAD without intercept
fit = ncvxHuberReg(X, Y)
fit$beta
# Fit Huber-MCP with intercept
fit = ncvxHuberReg(X, Y, penalty = "MCP", intercept = TRUE)
fit$beta
}
\references{
Fan, J., Liu, H., Sun, Q. and Zhang, T. (2018). I-LAMM for sparse learning: Simultaneous control of algorithmic complexity and statistical error. Ann. Statist. 46 814â€“841.
}
\seealso{
\code{\link{cvNcvxHuberReg}}
}
\author{
Xiaoou Pan, Qiang Sun, Wen-Xin Zhou
}
